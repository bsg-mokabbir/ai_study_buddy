{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéì AI Study Buddy Tutorial: From Text-Only to Multimodal Chatbot\n",
    "\n",
    "This comprehensive tutorial will guide you through building an AI Study Buddy chatbot step by step:\n",
    "\n",
    "1. **Phase 1**: Build a text-only educational chatbot\n",
    "2. **Phase 2**: Add image generation capabilities\n",
    "3. **Phase 3**: Create a complete Streamlit web interface\n",
    "\n",
    "We'll use the same modular architecture and code structure as the main project.\n",
    "\n",
    "## üìã Prerequisites\n",
    "\n",
    "- Python 3.8+\n",
    "- OpenAI API key\n",
    "- Basic understanding of Python and web development\n",
    "\n",
    "## üõ†Ô∏è Setup\n",
    "\n",
    "First, let's install the required packages and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (1.88.0)\n",
      "Requirement already satisfied: streamlit in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (1.46.0)\n",
      "Requirement already satisfied: python-dotenv in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (1.1.0)\n",
      "Requirement already satisfied: httpx in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (0.28.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from openai) (4.14.0)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from httpx) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from httpx) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from httpx) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from httpcore==1.*->httpx) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from streamlit) (6.1.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from streamlit) (8.2.1)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from streamlit) (2.3.0)\n",
      "Requirement already satisfied: packaging<26,>=20 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from streamlit) (25.0)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from streamlit) (2.3.0)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from streamlit) (11.2.1)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from streamlit) (6.31.1)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from streamlit) (20.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from streamlit) (2.32.4)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from streamlit) (9.1.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from streamlit) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from streamlit) (6.5.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from altair<6,>=4.0->streamlit) (1.42.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniconda/base/envs/personalized_edu_env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "‚úÖ Setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install openai streamlit python-dotenv httpx\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "from typing import List, Dict, Any, Optional, Union\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import from the restructured src directory\n",
    "# Note: In the main project, templates are now in src/templates/\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîë Environment Configuration\n",
    "\n",
    "Let's set up our environment variables and configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI API key loaded successfully!\n",
      "Key preview: sk-proj-FY...tokA\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Check if OpenAI API key is available\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not api_key:\n",
    "    print(\"‚ö†Ô∏è OpenAI API key not found!\")\n",
    "    print(\"Please create a .env file in the project root with:\")\n",
    "    print(\"OPENAI_API_KEY=your_api_key_here\")\n",
    "else:\n",
    "    print(\"‚úÖ OpenAI API key loaded successfully!\")\n",
    "    print(f\"Key preview: {api_key[:10]}...{api_key[-4:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìù Phase 1: Text-Only Educational Chatbot\n",
    "\n",
    "Let's start by building a simple text-only chatbot that can answer educational questions.\n",
    "\n",
    "## Step 1: Configuration Class\n",
    "\n",
    "First, we'll create a configuration class to manage our settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration created!\n",
      "Default model: gpt-3.5-turbo\n",
      "Supported subjects: Mathematics, Science, History, English/Literature, Geography, Study Tips\n"
     ]
    }
   ],
   "source": [
    "class TextChatbotConfig:\n",
    "    \"\"\"\n",
    "    Configuration for our text-only chatbot.\n",
    "    This is a simplified version of the main project's configuration.\n",
    "    \"\"\"\n",
    "    \n",
    "    # API Configuration\n",
    "    OPENAI_API_KEY: str = os.getenv('OPENAI_API_KEY', '')\n",
    "    \n",
    "    # Model Configuration\n",
    "    AVAILABLE_TEXT_MODELS: List[str] = [\n",
    "        'gpt-3.5-turbo',      # Fast and cost-effective\n",
    "        'gpt-4',              # More capable but slower\n",
    "        'gpt-4-turbo-preview' # Latest and most advanced\n",
    "    ]\n",
    "    DEFAULT_TEXT_MODEL: str = 'gpt-3.5-turbo'\n",
    "    \n",
    "    # Chat Configuration\n",
    "    MAX_TOKENS: int = 1000        # Maximum response length\n",
    "    TEMPERATURE: float = 0.7      # Creativity level (0.0-1.0)\n",
    "    MAX_CHAT_HISTORY: int = 20    # Number of messages to remember\n",
    "    \n",
    "    # Educational Content\n",
    "    SUPPORTED_SUBJECTS: List[str] = [\n",
    "        'Mathematics', 'Science', 'History', \n",
    "        'English/Literature', 'Geography', 'Study Tips'\n",
    "    ]\n",
    "\n",
    "# Create global config instance\n",
    "config = TextChatbotConfig()\n",
    "print(\"‚úÖ Configuration created!\")\n",
    "print(f\"Default model: {config.DEFAULT_TEXT_MODEL}\")\n",
    "print(f\"Supported subjects: {', '.join(config.SUPPORTED_SUBJECTS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Educational Prompts\n",
    "\n",
    "Now let's create our educational prompt templates that will guide the AI's behavior.\n",
    "\n",
    "**Note**: In the main project, this EducationalPrompts class is located in `src/templates/prompts.py` as part of the restructured architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Educational prompts created!\n",
      "Sample prompt length: 1178 characters\n"
     ]
    }
   ],
   "source": [
    "class EducationalPrompts:\n",
    "    \"\"\"\n",
    "    Educational prompt templates for the AI Study Buddy.\n",
    "    These prompts define how the AI should behave and respond.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Main system prompt that defines the AI's personality and role\n",
    "    SYSTEM_PROMPT: str = \"\"\"\n",
    "    You are an AI Study Buddy, a helpful educational assistant for high school students.\n",
    "    You help with subjects like Math, Science, History, English, and other academic topics.\n",
    "\n",
    "    Your personality and behavior:\n",
    "    - Be encouraging and supportive, like a friendly tutor\n",
    "    - Provide clear, step-by-step explanations\n",
    "    - Use examples that high school students can relate to\n",
    "    - Keep your language appropriate for teenagers\n",
    "    - Be patient and never make students feel bad for not knowing something\n",
    "    - Encourage curiosity and critical thinking\n",
    "\n",
    "    Your capabilities:\n",
    "    - Answer questions about academic subjects\n",
    "    - Explain complex concepts in simple terms\n",
    "    - Help with homework and study strategies\n",
    "    - Create practice questions and quizzes\n",
    "\n",
    "    What you should do:\n",
    "    - If asked non-educational questions, politely redirect to academic topics\n",
    "    - Always be encouraging and positive about learning\n",
    "    - Break down complex problems into smaller, manageable steps\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_educational_prompt(question: str, subject: str = 'general') -> str:\n",
    "        \"\"\"\n",
    "        Create a complete prompt for answering educational questions.\n",
    "        \n",
    "        Args:\n",
    "            question: The student's question\n",
    "            subject: The subject area (optional)\n",
    "            \n",
    "        Returns:\n",
    "            Complete prompt for the AI\n",
    "        \"\"\"\n",
    "        # Subject-specific guidance\n",
    "        subject_guidance = {\n",
    "            'science': \"Focus on scientific accuracy and the scientific method. Use examples from everyday life.\",\n",
    "            'math': \"Break down problems step-by-step. Show your work clearly. Use real-world applications.\",\n",
    "            'history': \"Provide historical context and connections between events. Use specific dates and facts.\",\n",
    "            'english': \"Focus on reading comprehension, writing skills, and literary analysis.\",\n",
    "            'geography': \"Use maps, statistics, and real-world examples. Connect geographical features to human activities.\",\n",
    "            'general': \"Adapt your response to the subject matter of the question.\"\n",
    "        }\n",
    "        \n",
    "        guidance = subject_guidance.get(subject.lower(), subject_guidance['general'])\n",
    "        \n",
    "        return f\"\"\"{EducationalPrompts.SYSTEM_PROMPT}\n",
    "        \n",
    "Subject-specific guidance: {guidance}\n",
    "\n",
    "Student Question: {question}\n",
    "\n",
    "Study Buddy Response:\"\"\"\n",
    "\n",
    "# Test the prompt creation\n",
    "prompts = EducationalPrompts()\n",
    "test_prompt = prompts.create_educational_prompt(\"What is photosynthesis?\", \"science\")\n",
    "print(\"‚úÖ Educational prompts created!\")\n",
    "print(f\"Sample prompt length: {len(test_prompt)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: OpenAI Service\n",
    "\n",
    "Now let's create a service to handle communication with OpenAI's API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to OpenAI successfully!\n",
      "Service available: True\n"
     ]
    }
   ],
   "source": [
    "import ssl\n",
    "import httpx\n",
    "from openai import OpenAI\n",
    "\n",
    "class TextChatbotService:\n",
    "    \"\"\"\n",
    "    Service for handling OpenAI API interactions for text generation.\n",
    "    This is a simplified version of the main project's OpenAI service.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the OpenAI service.\"\"\"\n",
    "        self.client: Optional[OpenAI] = None\n",
    "        self._initialize_client()\n",
    "    \n",
    "    def _initialize_client(self) -> None:\n",
    "        \"\"\"Set up the connection to OpenAI's servers.\"\"\"\n",
    "        if not config.OPENAI_API_KEY:\n",
    "            print(\"‚ùå OpenAI API key not found!\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # Try standard connection first\n",
    "            self.client = OpenAI(api_key=config.OPENAI_API_KEY)\n",
    "            print(\"‚úÖ Connected to OpenAI successfully!\")\n",
    "            \n",
    "        except Exception as error:\n",
    "            print(f\"‚ö†Ô∏è Connection issue: {error}\")\n",
    "            # Try with relaxed SSL settings for corporate networks\n",
    "            self._initialize_with_relaxed_ssl()\n",
    "    \n",
    "    def _initialize_with_relaxed_ssl(self) -> None:\n",
    "        \"\"\"Initialize with relaxed SSL settings for corporate networks.\"\"\"\n",
    "        try:\n",
    "            # Create HTTP client with relaxed security for corporate networks\n",
    "            http_client = httpx.Client(verify=False, timeout=30.0)\n",
    "            self.client = OpenAI(\n",
    "                api_key=config.OPENAI_API_KEY,\n",
    "                http_client=http_client\n",
    "            )\n",
    "            print(\"‚úÖ Connected with relaxed SSL settings\")\n",
    "            \n",
    "        except Exception as error:\n",
    "            print(f\"‚ùå Failed to connect: {error}\")\n",
    "    \n",
    "    def is_available(self) -> bool:\n",
    "        \"\"\"Check if the service is ready to use.\"\"\"\n",
    "        return self.client is not None\n",
    "    \n",
    "    def generate_response(self, messages: List[Dict[str, str]], \n",
    "                         model: str = None) -> Dict[str, Union[str, bool]]:\n",
    "        \"\"\"\n",
    "        Generate a text response using OpenAI's chat models.\n",
    "        \n",
    "        Args:\n",
    "            messages: List of conversation messages\n",
    "            model: Which AI model to use\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing the response and success status\n",
    "        \"\"\"\n",
    "        if not self.is_available():\n",
    "            return {\n",
    "                'success': False,\n",
    "                'text': 'OpenAI service is not available. Please check your connection.',\n",
    "                'error': 'Service unavailable'\n",
    "            }\n",
    "        \n",
    "        # Use default model if none specified\n",
    "        if model is None:\n",
    "            model = config.DEFAULT_TEXT_MODEL\n",
    "        \n",
    "        try:\n",
    "            # Send request to OpenAI\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                max_tokens=config.MAX_TOKENS,\n",
    "                temperature=config.TEMPERATURE\n",
    "            )\n",
    "            \n",
    "            # Extract the AI's response\n",
    "            response_text = response.choices[0].message.content.strip()\n",
    "            \n",
    "            return {\n",
    "                'success': True,\n",
    "                'text': response_text,\n",
    "                'model': model\n",
    "            }\n",
    "            \n",
    "        except Exception as error:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'text': f'Error generating response: {str(error)}',\n",
    "                'error': str(error)\n",
    "            }\n",
    "\n",
    "# Initialize the service\n",
    "openai_service = TextChatbotService()\n",
    "print(f\"Service available: {openai_service.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Text-Only Chatbot Class\n",
    "\n",
    "Now let's create our main chatbot class that brings everything together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Text-only chatbot initialized!\n",
      "‚úÖ Text-only chatbot ready!\n"
     ]
    }
   ],
   "source": [
    "class TextOnlyChatbot:\n",
    "    \"\"\"\n",
    "    A text-only educational chatbot.\n",
    "    This is the foundation that we'll later extend with image capabilities.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the chatbot.\"\"\"\n",
    "        self.conversation_history: List[Dict[str, str]] = []\n",
    "        self.prompts = EducationalPrompts()\n",
    "        self.service = openai_service\n",
    "        \n",
    "        # Add system message to start conversation\n",
    "        self.conversation_history.append({\n",
    "            'role': 'system',\n",
    "            'content': self.prompts.SYSTEM_PROMPT\n",
    "        })\n",
    "        \n",
    "        print(\"ü§ñ Text-only chatbot initialized!\")\n",
    "    \n",
    "    def ask(self, question: str, subject: str = 'general') -> str:\n",
    "        \"\"\"\n",
    "        Ask the chatbot a question and get a response.\n",
    "        \n",
    "        Args:\n",
    "            question: The student's question\n",
    "            subject: The subject area (optional)\n",
    "            \n",
    "        Returns:\n",
    "            The chatbot's response\n",
    "        \"\"\"\n",
    "        if not self.service.is_available():\n",
    "            return \"‚ùå Sorry, I'm not available right now. Please check your internet connection and API key.\"\n",
    "        \n",
    "        # Add user question to conversation\n",
    "        self.conversation_history.append({\n",
    "            'role': 'user',\n",
    "            'content': question\n",
    "        })\n",
    "        \n",
    "        # Generate response\n",
    "        response = self.service.generate_response(self.conversation_history)\n",
    "        \n",
    "        if response['success']:\n",
    "            # Add assistant response to conversation\n",
    "            self.conversation_history.append({\n",
    "                'role': 'assistant',\n",
    "                'content': response['text']\n",
    "            })\n",
    "            \n",
    "            # Keep conversation history manageable\n",
    "            self._trim_conversation_history()\n",
    "            \n",
    "            return response['text']\n",
    "        else:\n",
    "            return f\"‚ùå {response['text']}\"\n",
    "    \n",
    "    def _trim_conversation_history(self) -> None:\n",
    "        \"\"\"Keep conversation history within limits.\"\"\"\n",
    "        if len(self.conversation_history) > config.MAX_CHAT_HISTORY:\n",
    "            # Keep system message and recent messages\n",
    "            system_msg = self.conversation_history[0]\n",
    "            recent_msgs = self.conversation_history[-(config.MAX_CHAT_HISTORY-1):]\n",
    "            self.conversation_history = [system_msg] + recent_msgs\n",
    "    \n",
    "    def clear_history(self) -> None:\n",
    "        \"\"\"Clear conversation history but keep system message.\"\"\"\n",
    "        system_msg = self.conversation_history[0]\n",
    "        self.conversation_history = [system_msg]\n",
    "        print(\"üßπ Conversation history cleared!\")\n",
    "    \n",
    "    def get_conversation_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get statistics about the current conversation.\"\"\"\n",
    "        user_messages = sum(1 for msg in self.conversation_history if msg['role'] == 'user')\n",
    "        assistant_messages = sum(1 for msg in self.conversation_history if msg['role'] == 'assistant')\n",
    "        \n",
    "        return {\n",
    "            'total_messages': len(self.conversation_history),\n",
    "            'user_messages': user_messages,\n",
    "            'assistant_messages': assistant_messages,\n",
    "            'service_available': self.service.is_available()\n",
    "        }\n",
    "\n",
    "# Create our text-only chatbot\n",
    "chatbot = TextOnlyChatbot()\n",
    "print(\"‚úÖ Text-only chatbot ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Testing the Text-Only Chatbot\n",
    "\n",
    "Let's test our text-only chatbot with some educational questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing Text-Only Chatbot\n",
      "==================================================\n",
      "\n",
      "üìù Test 1: Science\n",
      "Question: What is photosynthesis?\n",
      "------------------------------\n",
      "Response: Photosynthesis is a process that plants, algae, and some bacteria use to convert light energy, usually from the sun, into chemical energy in the form of glucose (a type of sugar). This process is esse...\n",
      "\n",
      "\n",
      "üìù Test 2: Math\n",
      "Question: How do I solve x¬≤ + 5x + 6 = 0?\n",
      "------------------------------\n",
      "Response: To solve the quadratic equation x¬≤ + 5x + 6 = 0, you can use the factoring method or the quadratic formula. Let's use the factoring method in this case:\n",
      "\n",
      "1. Write the equation in the form ax¬≤ + bx + c...\n",
      "\n",
      "\n",
      "üìù Test 3: History\n",
      "Question: What caused World War I?\n",
      "------------------------------\n",
      "Response: World War I, also known as the Great War, was caused by a combination of several factors that had been building up over time. Here are some key reasons that led to the outbreak of World War I:\n",
      "\n",
      "1. **M...\n",
      "\n",
      "\n",
      "üìù Test 4: English\n",
      "Question: Explain the difference between metaphor and simile\n",
      "------------------------------\n",
      "Response: Metaphors and similes are both figures of speech used to make comparisons, but they do so in slightly different ways:\n",
      "\n",
      "1. **Metaphor**:\n",
      "   - A metaphor directly compares two different things by statin...\n",
      "\n",
      "üìä Conversation Statistics:\n",
      "  total_messages: 9\n",
      "  user_messages: 4\n",
      "  assistant_messages: 4\n",
      "  service_available: True\n"
     ]
    }
   ],
   "source": [
    "# Test questions for different subjects\n",
    "test_questions = [\n",
    "    (\"What is photosynthesis?\", \"science\"),\n",
    "    (\"How do I solve x¬≤ + 5x + 6 = 0?\", \"math\"),\n",
    "    (\"What caused World War I?\", \"history\"),\n",
    "    (\"Explain the difference between metaphor and simile\", \"english\")\n",
    "]\n",
    "\n",
    "print(\"üß™ Testing Text-Only Chatbot\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, (question, subject) in enumerate(test_questions, 1):\n",
    "    print(f\"\\nüìù Test {i}: {subject.title()}\")\n",
    "    print(f\"Question: {question}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Get response from chatbot\n",
    "    response = chatbot.ask(question, subject)\n",
    "    print(f\"Response: {response[:200]}...\" if len(response) > 200 else f\"Response: {response}\")\n",
    "    print()\n",
    "\n",
    "# Show conversation statistics\n",
    "stats = chatbot.get_conversation_stats()\n",
    "print(\"üìä Conversation Statistics:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé® Phase 2: Adding Image Generation Capabilities\n",
    "\n",
    "Now let's extend our text-only chatbot to support image generation using DALL-E.\n",
    "\n",
    "## Step 1: Enhanced Configuration\n",
    "\n",
    "First, let's update our configuration to include image generation settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Enhanced configuration created!\n",
      "Image model: dall-e-3\n",
      "Image keywords: 28 patterns\n"
     ]
    }
   ],
   "source": [
    "class MultimodalChatbotConfig(TextChatbotConfig):\n",
    "    \"\"\"\n",
    "    Enhanced configuration that includes image generation capabilities.\n",
    "    This extends our text-only configuration.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Image Generation Configuration\n",
    "    IMAGE_MODEL: str = 'dall-e-3'           # DALL-E model for image generation\n",
    "    DEFAULT_IMAGE_SIZE: str = '1024x1024'   # Default image dimensions\n",
    "    IMAGE_QUALITY: str = 'standard'         # Image quality ('standard' or 'hd')\n",
    "    IMAGES_PER_REQUEST: int = 1              # Number of images to generate\n",
    "    \n",
    "    # Keywords that indicate image generation requests\n",
    "    IMAGE_REQUEST_KEYWORDS: List[str] = [\n",
    "        'create an image', 'generate an image', 'make an image', 'draw an image',\n",
    "        'create a picture', 'generate a picture', 'make a picture', 'draw a picture',\n",
    "        'show me an image', 'show me a picture', 'visualize', 'illustrate',\n",
    "        'create art', 'generate art', 'make art', 'draw art',\n",
    "        'design', 'sketch', 'paint', 'render',\n",
    "        'draw me', 'show me a', 'can you draw', 'can you create',\n",
    "        'can you generate', 'can you make', 'i want an image', 'i want a picture'\n",
    "    ]\n",
    "\n",
    "# Update our global config\n",
    "config = MultimodalChatbotConfig()\n",
    "print(\"‚úÖ Enhanced configuration created!\")\n",
    "print(f\"Image model: {config.IMAGE_MODEL}\")\n",
    "print(f\"Image keywords: {len(config.IMAGE_REQUEST_KEYWORDS)} patterns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Image Detection Helper\n",
    "\n",
    "Let's create a helper function to detect when users want images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Testing Image Detection:\n",
      "  'What is photosynthesis?' ‚Üí üìù Text\n",
      "  'Create an image of a solar system' ‚Üí üé® Image\n",
      "  'Explain gravity' ‚Üí üìù Text\n",
      "  'Draw me a picture of a DNA molecule' ‚Üí üé® Image\n",
      "  'Can you generate an image of ancient Rome?' ‚Üí üé® Image\n"
     ]
    }
   ],
   "source": [
    "def detect_image_request(user_input: str) -> bool:\n",
    "    \"\"\"\n",
    "    Determine if the user is asking for an image to be created.\n",
    "    \n",
    "    This function analyzes the user's input to decide whether they want\n",
    "    an image generated or just a text response.\n",
    "    \n",
    "    Args:\n",
    "        user_input: What the user typed\n",
    "        \n",
    "    Returns:\n",
    "        True if they want an image, False if they want text\n",
    "    \"\"\"\n",
    "    # Convert to lowercase for easier matching\n",
    "    user_input_lower = user_input.lower()\n",
    "    \n",
    "    # Check if any image request keywords are in the user's message\n",
    "    for keyword in config.IMAGE_REQUEST_KEYWORDS:\n",
    "        if keyword in user_input_lower:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# Test the image detection\n",
    "test_inputs = [\n",
    "    \"What is photosynthesis?\",                    # Text\n",
    "    \"Create an image of a solar system\",          # Image\n",
    "    \"Explain gravity\",                            # Text\n",
    "    \"Draw me a picture of a DNA molecule\",        # Image\n",
    "    \"Can you generate an image of ancient Rome?\"  # Image\n",
    "]\n",
    "\n",
    "print(\"üîç Testing Image Detection:\")\n",
    "for test_input in test_inputs:\n",
    "    is_image = detect_image_request(test_input)\n",
    "    print(f\"  '{test_input}' ‚Üí {'üé® Image' if is_image else 'üìù Text'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Enhanced Service with Image Generation\n",
    "\n",
    "Now let's extend our service to handle both text and image generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to OpenAI successfully!\n",
      "‚úÖ Enhanced service created! Available: True\n"
     ]
    }
   ],
   "source": [
    "class MultimodalChatbotService(TextChatbotService):\n",
    "    \"\"\"\n",
    "    Enhanced service that supports both text and image generation.\n",
    "    This extends our text-only service.\n",
    "    \"\"\"\n",
    "    \n",
    "    def generate_image(self, prompt: str) -> Dict[str, Union[str, bool]]:\n",
    "        \"\"\"\n",
    "        Generate an image using OpenAI's DALL-E model.\n",
    "        \n",
    "        Args:\n",
    "            prompt: Text description of the image to create\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing the image URL and success status\n",
    "        \"\"\"\n",
    "        if not self.is_available():\n",
    "            return {\n",
    "                'success': False,\n",
    "                'text': 'OpenAI service is not available. Please check your connection.',\n",
    "                'error': 'Service unavailable'\n",
    "            }\n",
    "        \n",
    "        try:\n",
    "            # Clean up the prompt for better image generation\n",
    "            cleaned_prompt = self._clean_image_prompt(prompt)\n",
    "            \n",
    "            # Generate image using DALL-E\n",
    "            response = self.client.images.generate(\n",
    "                model=config.IMAGE_MODEL,\n",
    "                prompt=cleaned_prompt,\n",
    "                size=config.DEFAULT_IMAGE_SIZE,\n",
    "                quality=config.IMAGE_QUALITY,\n",
    "                n=config.IMAGES_PER_REQUEST,\n",
    "            )\n",
    "            \n",
    "            # Get the image URL from the response\n",
    "            image_url = response.data[0].url\n",
    "            \n",
    "            return {\n",
    "                'success': True,\n",
    "                'type': 'image',\n",
    "                'url': image_url,\n",
    "                'prompt': cleaned_prompt,\n",
    "                'text': f\"I've created an image based on your request: '{cleaned_prompt}'\"\n",
    "            }\n",
    "            \n",
    "        except Exception as error:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'text': f'Error generating image: {str(error)}',\n",
    "                'error': str(error)\n",
    "            }\n",
    "    \n",
    "    def _clean_image_prompt(self, prompt: str) -> str:\n",
    "        \"\"\"\n",
    "        Clean up the user's prompt for better image generation.\n",
    "        \n",
    "        This removes common phrases like \"create an image of\" to make\n",
    "        the prompt more focused on the actual content.\n",
    "        \"\"\"\n",
    "        # Remove common request phrases\n",
    "        phrases_to_remove = [\n",
    "            'create an image of', 'generate an image of', 'make an image of',\n",
    "            'draw an image of', 'show me an image of', 'create a picture of',\n",
    "            'generate a picture of', 'make a picture of', 'draw a picture of',\n",
    "            'show me a picture of', 'visualize', 'illustrate', 'draw me'\n",
    "        ]\n",
    "        \n",
    "        cleaned = prompt.lower()\n",
    "        for phrase in phrases_to_remove:\n",
    "            cleaned = cleaned.replace(phrase, '')\n",
    "        \n",
    "        return cleaned.strip()\n",
    "\n",
    "# Create enhanced service\n",
    "enhanced_service = MultimodalChatbotService()\n",
    "print(f\"‚úÖ Enhanced service created! Available: {enhanced_service.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Multimodal Chatbot Class\n",
    "\n",
    "Now let's create our enhanced chatbot that can handle both text and images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Text-only chatbot initialized!\n",
      "üé® Multimodal chatbot initialized!\n",
      "‚úÖ Multimodal chatbot ready!\n"
     ]
    }
   ],
   "source": [
    "class MultimodalChatbot(TextOnlyChatbot):\n",
    "    \"\"\"\n",
    "    Enhanced chatbot that supports both text and image generation.\n",
    "    This extends our text-only chatbot.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the multimodal chatbot.\"\"\"\n",
    "        # Initialize parent class\n",
    "        super().__init__()\n",
    "        \n",
    "        # Use enhanced service\n",
    "        self.service = enhanced_service\n",
    "        \n",
    "        print(\"üé® Multimodal chatbot initialized!\")\n",
    "    \n",
    "    def ask(self, question: str, subject: str = 'general') -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Ask the chatbot a question and get either text or image response.\n",
    "        \n",
    "        Args:\n",
    "            question: The student's question\n",
    "            subject: The subject area (optional)\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing the response and metadata\n",
    "        \"\"\"\n",
    "        if not self.service.is_available():\n",
    "            return {\n",
    "                'success': False,\n",
    "                'type': 'error',\n",
    "                'text': \"‚ùå Sorry, I'm not available right now. Please check your internet connection and API key.\"\n",
    "            }\n",
    "        \n",
    "        # Detect if user wants an image\n",
    "        wants_image = detect_image_request(question)\n",
    "        \n",
    "        if wants_image:\n",
    "            return self._handle_image_request(question)\n",
    "        else:\n",
    "            return self._handle_text_request(question, subject)\n",
    "    \n",
    "    def _handle_image_request(self, question: str) -> Dict[str, Any]:\n",
    "        \"\"\"Handle image generation requests.\"\"\"\n",
    "        # Generate image\n",
    "        response = self.service.generate_image(question)\n",
    "        \n",
    "        if response['success']:\n",
    "            # Add to conversation history\n",
    "            self.conversation_history.append({\n",
    "                'role': 'user',\n",
    "                'content': question\n",
    "            })\n",
    "            self.conversation_history.append({\n",
    "                'role': 'assistant',\n",
    "                'content': response['text']\n",
    "            })\n",
    "            \n",
    "            return {\n",
    "                'success': True,\n",
    "                'type': 'image',\n",
    "                'url': response['url'],\n",
    "                'text': response['text'],\n",
    "                'prompt': response['prompt']\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'type': 'error',\n",
    "                'text': f\"‚ùå {response['text']}\"\n",
    "            }\n",
    "    \n",
    "    def _handle_text_request(self, question: str, subject: str) -> Dict[str, Any]:\n",
    "        \"\"\"Handle text generation requests.\"\"\"\n",
    "        # Add user question to conversation\n",
    "        self.conversation_history.append({\n",
    "            'role': 'user',\n",
    "            'content': question\n",
    "        })\n",
    "        \n",
    "        # Generate text response\n",
    "        response = self.service.generate_response(self.conversation_history)\n",
    "        \n",
    "        if response['success']:\n",
    "            # Add assistant response to conversation\n",
    "            self.conversation_history.append({\n",
    "                'role': 'assistant',\n",
    "                'content': response['text']\n",
    "            })\n",
    "            \n",
    "            # Keep conversation history manageable\n",
    "            self._trim_conversation_history()\n",
    "            \n",
    "            return {\n",
    "                'success': True,\n",
    "                'type': 'text',\n",
    "                'text': response['text']\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'type': 'error',\n",
    "                'text': f\"‚ùå {response['text']}\"\n",
    "            }\n",
    "\n",
    "# Create our multimodal chatbot\n",
    "multimodal_chatbot = MultimodalChatbot()\n",
    "print(\"‚úÖ Multimodal chatbot ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Testing the Multimodal Chatbot\n",
    "\n",
    "Let's test our enhanced chatbot with both text and image requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing Multimodal Chatbot\n",
      "==================================================\n",
      "\n",
      "üîÑ Test 1: Science\n",
      "Request: What is photosynthesis?\n",
      "------------------------------\n",
      "üìù Text Response: Photosynthesis is the process by which plants, algae, and some bacteria convert light energy, usually from the sun, into chemical energy stored in glucose (sugar). This process is crucial for life on ...\n",
      "\n",
      "\n",
      "üîÑ Test 2: Science\n",
      "Request: Create an image of a solar system\n",
      "------------------------------\n",
      "üé® Image Generated!\n",
      "   URL: https://oaidalleapiprodscus.blob.core.windows.net/private/org-YMTWaeU9jWDeGYEPGVSEdkw1/user-BoguSZL7EQw4k7sCZmG4KXyw/img-fwGsxEfytRFAUtEquAaXWkN7.png?st=2025-06-19T06%3A26%3A55Z&se=2025-06-19T08%3A26%3A55Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=475fd488-6c59-44a5-9aa9-31c4db451bea&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-06-18T10%3A06%3A18Z&ske=2025-06-19T10%3A06%3A18Z&sks=b&skv=2024-08-04&sig=q5bu4XsA61H8pUO%2Brer9YopsHPGUCTrzKwPS%2BSOiDrE%3D\n",
      "   Description: I've created an image based on your request: 'a solar system'\n",
      "   Cleaned Prompt: a solar system\n",
      "\n",
      "\n",
      "üîÑ Test 3: Math\n",
      "Request: How do I solve quadratic equations?\n",
      "------------------------------\n",
      "üìù Text Response: Solving quadratic equations involves finding the values of the variable that make the equation true. The standard form of a quadratic equation is \\( ax^2 + bx + c = 0 \\), where \\( a \\), \\( b \\), and \\...\n",
      "\n",
      "\n",
      "üîÑ Test 4: History\n",
      "Request: Draw me a picture of ancient Rome\n",
      "------------------------------\n",
      "üé® Image Generated!\n",
      "   URL: https://oaidalleapiprodscus.blob.core.windows.net/private/org-YMTWaeU9jWDeGYEPGVSEdkw1/user-BoguSZL7EQw4k7sCZmG4KXyw/img-1rXzlICOJWtCoUW7ynoj6hOt.png?st=2025-06-19T06%3A27%3A13Z&se=2025-06-19T08%3A27%3A13Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=475fd488-6c59-44a5-9aa9-31c4db451bea&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-06-19T07%3A27%3A13Z&ske=2025-06-20T07%3A27%3A13Z&sks=b&skv=2024-08-04&sig=whut7GmDORWfusZvdpbPO3AK2vwIz8F444BL28ueoc0%3D\n",
      "   Description: I've created an image based on your request: 'a picture of ancient rome'\n",
      "   Cleaned Prompt: a picture of ancient rome\n",
      "\n",
      "üìä Updated Conversation Statistics:\n",
      "  total_messages: 9\n",
      "  user_messages: 4\n",
      "  assistant_messages: 4\n",
      "  service_available: True\n"
     ]
    }
   ],
   "source": [
    "# Test both text and image requests\n",
    "test_requests = [\n",
    "    (\"What is photosynthesis?\", \"science\"),                    # Text\n",
    "    (\"Create an image of a solar system\", \"science\"),          # Image\n",
    "    (\"How do I solve quadratic equations?\", \"math\"),           # Text\n",
    "    (\"Draw me a picture of ancient Rome\", \"history\"),          # Image\n",
    "]\n",
    "\n",
    "print(\"üß™ Testing Multimodal Chatbot\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, (request, subject) in enumerate(test_requests, 1):\n",
    "    print(f\"\\nüîÑ Test {i}: {subject.title()}\")\n",
    "    print(f\"Request: {request}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Get response from multimodal chatbot\n",
    "    response = multimodal_chatbot.ask(request, subject)\n",
    "    \n",
    "    if response['success']:\n",
    "        if response['type'] == 'text':\n",
    "            print(f\"üìù Text Response: {response['text'][:200]}...\" if len(response['text']) > 200 else f\"üìù Text Response: {response['text']}\")\n",
    "        elif response['type'] == 'image':\n",
    "            print(f\"üé® Image Generated!\")\n",
    "            print(f\"   URL: {response['url']}\")\n",
    "            print(f\"   Description: {response['text']}\")\n",
    "            print(f\"   Cleaned Prompt: {response['prompt']}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Error: {response['text']}\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "# Show updated conversation statistics\n",
    "stats = multimodal_chatbot.get_conversation_stats()\n",
    "print(\"üìä Updated Conversation Statistics:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåê Phase 3: Creating a Streamlit Web Interface\n",
    "\n",
    "Now let's create a complete web interface using Streamlit, just like the main project.\n",
    "\n",
    "## Step 1: Streamlit App Class\n",
    "\n",
    "Let's create a Streamlit app that uses our multimodal chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Streamlit app class created!\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "class StudyBuddyStreamlitApp:\n",
    "    \"\"\"\n",
    "    Streamlit web interface for the AI Study Buddy.\n",
    "    This creates the same interface as the main project.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the Streamlit app.\"\"\"\n",
    "        self.chatbot = multimodal_chatbot\n",
    "        self._setup_page_config()\n",
    "        self._initialize_session_state()\n",
    "    \n",
    "    def _setup_page_config(self):\n",
    "        \"\"\"Configure the Streamlit page settings.\"\"\"\n",
    "        st.set_page_config(\n",
    "            page_title=\"AI Study Buddy\",\n",
    "            page_icon=\"üéì\",\n",
    "            layout=\"wide\",\n",
    "            initial_sidebar_state=\"expanded\"\n",
    "        )\n",
    "    \n",
    "    def _initialize_session_state(self):\n",
    "        \"\"\"Initialize Streamlit session state variables.\"\"\"\n",
    "        if 'messages' not in st.session_state:\n",
    "            st.session_state.messages = []\n",
    "        \n",
    "        if 'conversation_count' not in st.session_state:\n",
    "            st.session_state.conversation_count = 0\n",
    "        \n",
    "        if 'selected_model' not in st.session_state:\n",
    "            st.session_state.selected_model = config.DEFAULT_TEXT_MODEL\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"Run the main Streamlit application.\"\"\"\n",
    "        # Apply custom styling\n",
    "        self._apply_custom_styling()\n",
    "        \n",
    "        # Display header\n",
    "        self._display_header()\n",
    "        \n",
    "        # Create sidebar\n",
    "        self._create_sidebar()\n",
    "        \n",
    "        # Display chat messages\n",
    "        self._display_chat_messages()\n",
    "        \n",
    "        # Handle chat input\n",
    "        self._handle_chat_input()\n",
    "    \n",
    "    def _apply_custom_styling(self):\n",
    "        \"\"\"Apply custom CSS styling to the app.\"\"\"\n",
    "        st.markdown(\"\"\"\n",
    "        <style>\n",
    "        .main-header {\n",
    "            text-align: center;\n",
    "            color: #1f77b4;\n",
    "            margin-bottom: 2rem;\n",
    "        }\n",
    "        .chat-message {\n",
    "            padding: 1rem;\n",
    "            margin: 0.5rem 0;\n",
    "            border-radius: 10px;\n",
    "        }\n",
    "        .user-message {\n",
    "            background-color: #e3f2fd;\n",
    "            border-left: 4px solid #2196f3;\n",
    "        }\n",
    "        .assistant-message {\n",
    "            background-color: #f3e5f5;\n",
    "            border-left: 4px solid #9c27b0;\n",
    "        }\n",
    "        </style>\n",
    "        \"\"\", unsafe_allow_html=True)\n",
    "    \n",
    "    def _display_header(self):\n",
    "        \"\"\"Display the main header.\"\"\"\n",
    "        st.markdown('<h1 class=\"main-header\">üéì AI Study Buddy</h1>', unsafe_allow_html=True)\n",
    "        st.markdown(\"<p style='text-align: center; color: #666;'>Your intelligent companion for learning and homework help!</p>\", unsafe_allow_html=True)\n",
    "        st.markdown(\"---\")\n",
    "\n",
    "print(\"‚úÖ Streamlit app class created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Sidebar and Chat Interface Methods\n",
    "\n",
    "Let's add the sidebar and chat interface methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Streamlit interface methods added!\n"
     ]
    }
   ],
   "source": [
    "# Add methods to the StudyBuddyStreamlitApp class\n",
    "def _create_sidebar(self):\n",
    "    \"\"\"Create the sidebar with controls and information.\"\"\"\n",
    "    with st.sidebar:\n",
    "        st.header(\"üéõÔ∏è Controls\")\n",
    "        \n",
    "        # Model selection\n",
    "        st.session_state.selected_model = st.selectbox(\n",
    "            \"Choose AI Model:\",\n",
    "            config.AVAILABLE_TEXT_MODELS,\n",
    "            index=config.AVAILABLE_TEXT_MODELS.index(st.session_state.selected_model)\n",
    "        )\n",
    "        \n",
    "        # Clear chat button\n",
    "        if st.button(\"üßπ Clear Chat\", use_container_width=True):\n",
    "            st.session_state.messages = []\n",
    "            st.session_state.conversation_count = 0\n",
    "            self.chatbot.clear_history()\n",
    "            st.rerun()\n",
    "        \n",
    "        st.markdown(\"---\")\n",
    "        \n",
    "        # Example questions\n",
    "        st.header(\"üí° Example Questions\")\n",
    "        \n",
    "        example_questions = [\n",
    "            \"What is photosynthesis?\",\n",
    "            \"How do I solve x¬≤ + 5x + 6 = 0?\",\n",
    "            \"What caused World War I?\",\n",
    "            \"Create an image of a DNA molecule\",\n",
    "            \"Draw me a picture of the solar system\"\n",
    "        ]\n",
    "        \n",
    "        for question in example_questions:\n",
    "            if st.button(question, key=f\"example_{question[:20]}\", use_container_width=True):\n",
    "                # Add the example question as if the user typed it\n",
    "                self._process_user_input(question)\n",
    "                st.rerun()\n",
    "        \n",
    "        st.markdown(\"---\")\n",
    "        \n",
    "        # Statistics\n",
    "        st.header(\"üìä Statistics\")\n",
    "        stats = self.chatbot.get_conversation_stats()\n",
    "        st.metric(\"Messages\", stats['total_messages'])\n",
    "        st.metric(\"Questions Asked\", stats['user_messages'])\n",
    "        st.metric(\"Responses Given\", stats['assistant_messages'])\n",
    "        \n",
    "        # Service status\n",
    "        status = \"üü¢ Online\" if stats['service_available'] else \"üî¥ Offline\"\n",
    "        st.metric(\"Service Status\", status)\n",
    "\n",
    "def _display_chat_messages(self):\n",
    "    \"\"\"Display all chat messages.\"\"\"\n",
    "    for message in st.session_state.messages:\n",
    "        with st.chat_message(message[\"role\"]):\n",
    "            if message[\"role\"] == \"user\":\n",
    "                st.write(message[\"content\"])\n",
    "            else:\n",
    "                # Handle different types of assistant responses\n",
    "                content = message[\"content\"]\n",
    "                if isinstance(content, dict):\n",
    "                    if content.get('type') == 'image':\n",
    "                        st.write(content['text'])\n",
    "                        try:\n",
    "                            # Display the image\n",
    "                            response = requests.get(content['url'])\n",
    "                            img = Image.open(BytesIO(response.content))\n",
    "                            st.image(img, caption=f\"Generated image: {content['prompt']}\", use_column_width=True)\n",
    "                        except Exception as e:\n",
    "                            st.error(f\"Could not display image: {e}\")\n",
    "                            st.write(f\"Image URL: {content['url']}\")\n",
    "                    else:\n",
    "                        st.write(content.get('text', str(content)))\n",
    "                else:\n",
    "                    st.write(content)\n",
    "\n",
    "def _handle_chat_input(self):\n",
    "    \"\"\"Handle user input from the chat interface.\"\"\"\n",
    "    if prompt := st.chat_input(\"Ask me anything about your studies, or request an image!\"):\n",
    "        self._process_user_input(prompt)\n",
    "\n",
    "def _process_user_input(self, user_input: str):\n",
    "    \"\"\"Process user input and generate response.\"\"\"\n",
    "    # Add user message to chat\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    \n",
    "    # Display user message\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.write(user_input)\n",
    "    \n",
    "    # Generate and display assistant response\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        with st.spinner(\"Thinking...\"):\n",
    "            response = self.chatbot.ask(user_input)\n",
    "            \n",
    "            if response['success']:\n",
    "                if response['type'] == 'text':\n",
    "                    st.write(response['text'])\n",
    "                    # Add to session state\n",
    "                    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response['text']})\n",
    "                    \n",
    "                elif response['type'] == 'image':\n",
    "                    st.write(response['text'])\n",
    "                    try:\n",
    "                        # Display the image\n",
    "                        img_response = requests.get(response['url'])\n",
    "                        img = Image.open(BytesIO(img_response.content))\n",
    "                        st.image(img, caption=f\"Generated image: {response['prompt']}\", use_column_width=True)\n",
    "                        \n",
    "                        # Add to session state\n",
    "                        st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        st.error(f\"Could not display image: {e}\")\n",
    "                        st.write(f\"Image URL: {response['url']}\")\n",
    "                        \n",
    "                        # Add error to session state\n",
    "                        st.session_state.messages.append({\"role\": \"assistant\", \"content\": f\"Image generated but could not display: {response['url']}\"})\n",
    "            else:\n",
    "                st.error(response['text'])\n",
    "                # Add error to session state\n",
    "                st.session_state.messages.append({\"role\": \"assistant\", \"content\": response['text']})\n",
    "    \n",
    "    # Update conversation count\n",
    "    st.session_state.conversation_count += 1\n",
    "\n",
    "# Add methods to the class\n",
    "StudyBuddyStreamlitApp._create_sidebar = _create_sidebar\n",
    "StudyBuddyStreamlitApp._display_chat_messages = _display_chat_messages\n",
    "StudyBuddyStreamlitApp._handle_chat_input = _handle_chat_input\n",
    "StudyBuddyStreamlitApp._process_user_input = _process_user_input\n",
    "\n",
    "print(\"‚úÖ Streamlit interface methods added!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Creating and Running the App\n",
    "\n",
    "Now let's create our complete Streamlit app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-19 13:27:59.558 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-19 13:27:59.559 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-19 13:27:59.559 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n",
      "2025-06-19 13:27:59.559 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-19 13:27:59.560 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-19 13:27:59.560 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-19 13:27:59.560 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-19 13:27:59.560 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-19 13:27:59.561 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-19 13:27:59.561 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-19 13:27:59.561 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Complete Streamlit app created!\n",
      "\n",
      "üöÄ To run the app, save this code to a .py file and run:\n",
      "   streamlit run your_app_file.py\n",
      "\n",
      "üìù Or copy the code below to create a standalone app file:\n"
     ]
    }
   ],
   "source": [
    "# Create the complete Streamlit app\n",
    "streamlit_app = StudyBuddyStreamlitApp()\n",
    "print(\"‚úÖ Complete Streamlit app created!\")\n",
    "print(\"\\nüöÄ To run the app, save this code to a .py file and run:\")\n",
    "print(\"   streamlit run your_app_file.py\")\n",
    "print(\"\\nüìù Or copy the code below to create a standalone app file:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Standalone App File\n",
    "\n",
    "Here's the complete code for a standalone Streamlit app file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standalone_app_code = '''\n",
    "# AI Study Buddy - Complete Streamlit App\n",
    "# Save this as app.py and run with: streamlit run app.py\n",
    "\n",
    "import os\n",
    "import streamlit as st\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import httpx\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from typing import List, Dict, Any, Optional, Union\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# [Include all the classes we created above: \n",
    "#  MultimodalChatbotConfig, EducationalPrompts, \n",
    "#  MultimodalChatbotService, MultimodalChatbot, \n",
    "#  StudyBuddyStreamlitApp]\n",
    "#\n",
    "# Note: In the main project, these classes are organized in:\n",
    "# - src/config/settings.py (Config classes)\n",
    "# - src/templates/prompts.py (EducationalPrompts)\n",
    "# - src/services/openai_service.py (Service classes)\n",
    "# - src/main.py (Chatbot classes)\n",
    "# - src/components/chat_interface.py (UI components)\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the Streamlit app.\"\"\"\n",
    "    app = StudyBuddyStreamlitApp()\n",
    "    app.run()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "print(\"üìÑ Standalone app code template created!\")\n",
    "print(\"\\nüí° To create a complete app file:\")\n",
    "print(\"1. Copy all the class definitions from this notebook\")\n",
    "print(\"2. Add them to the standalone app template above\")\n",
    "print(\"3. Save as 'app.py'\")\n",
    "print(\"4. Run with: streamlit run app.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéâ Tutorial Complete!\n",
    "\n",
    "Congratulations! You've successfully built a complete AI Study Buddy application from scratch.\n",
    "\n",
    "## üìö What You've Learned\n",
    "\n",
    "### Phase 1: Text-Only Chatbot\n",
    "- ‚úÖ **Configuration Management**: Created a flexible config system\n",
    "- ‚úÖ **Educational Prompts**: Designed prompts for educational interactions\n",
    "- ‚úÖ **OpenAI Integration**: Connected to OpenAI's text generation API\n",
    "- ‚úÖ **Conversation Management**: Built a chatbot with memory\n",
    "\n",
    "### Phase 2: Image Generation\n",
    "- ‚úÖ **Multimodal Capabilities**: Extended to support both text and images\n",
    "- ‚úÖ **Intent Detection**: Automatically detected image vs text requests\n",
    "- ‚úÖ **DALL-E Integration**: Added image generation with DALL-E 3\n",
    "- ‚úÖ **Enhanced Responses**: Created rich response objects\n",
    "\n",
    "### Phase 3: Web Interface\n",
    "- ‚úÖ **Streamlit Integration**: Built a complete web interface\n",
    "- ‚úÖ **Interactive UI**: Added sidebar controls and example questions\n",
    "- ‚úÖ **Image Display**: Handled image rendering in the web interface\n",
    "- ‚úÖ **Session Management**: Maintained conversation state across interactions\n",
    "\n",
    "## üõ†Ô∏è Key Features Implemented\n",
    "\n",
    "1. **Educational Focus**: Specialized prompts for learning\n",
    "2. **Subject Awareness**: Different approaches for different subjects\n",
    "3. **Multimodal Responses**: Both text explanations and visual aids\n",
    "4. **User-Friendly Interface**: Clean, intuitive web interface\n",
    "5. **Error Handling**: Robust error handling and fallbacks\n",
    "6. **Conversation Memory**: Maintains context across interactions\n",
    "7. **Example Questions**: Pre-built questions to get users started\n",
    "8. **Statistics Tracking**: Real-time conversation statistics\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "To extend this project further, you could:\n",
    "\n",
    "1. **Add More Subjects**: Expand the educational prompts\n",
    "2. **Implement Quizzes**: Add interactive quiz generation\n",
    "3. **File Upload**: Allow students to upload homework for help\n",
    "4. **Voice Integration**: Add speech-to-text and text-to-speech\n",
    "5. **Progress Tracking**: Track learning progress over time\n",
    "6. **Multi-Language**: Support multiple languages\n",
    "7. **Advanced Styling**: Enhance the UI with custom themes\n",
    "8. **Database Integration**: Store conversations and user progress\n",
    "\n",
    "## üìñ Code Architecture\n",
    "\n",
    "The tutorial follows the same modular architecture as the main project:\n",
    "\n",
    "- **Configuration Layer** (`src/config/`): Centralized settings and prompts\n",
    "- **Templates Layer** (`src/templates/`): Educational prompt templates\n",
    "- **Service Layer** (`src/services/`): OpenAI API integration and communication\n",
    "- **Utils Layer** (`src/utils/`): Helper functions and utilities\n",
    "- **Components Layer** (`src/components/`): UI components and interface elements\n",
    "- **Business Logic Layer** (`src/main.py`): Chatbot intelligence and conversation management\n",
    "- **Presentation Layer**: Streamlit web interface\n",
    "\n",
    "This architecture makes the code:\n",
    "- **Maintainable**: Easy to update and modify\n",
    "- **Testable**: Each component can be tested independently\n",
    "- **Scalable**: Easy to add new features\n",
    "- **Reusable**: Components can be used in other projects\n",
    "- **Organized**: Clear separation of concerns with all source code in `src/`\n",
    "\n",
    "## üéì Educational Value\n",
    "\n",
    "This tutorial demonstrates:\n",
    "- **Progressive Development**: Building complexity step by step\n",
    "- **Object-Oriented Design**: Using classes and inheritance effectively\n",
    "- **API Integration**: Working with external services\n",
    "- **Web Development**: Creating interactive web applications\n",
    "- **Error Handling**: Building robust, production-ready code\n",
    "- **User Experience**: Designing intuitive interfaces\n",
    "\n",
    "Thank you for following along! You now have the knowledge to build sophisticated AI-powered educational applications. üéâüìöü§ñ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personalized_edu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
